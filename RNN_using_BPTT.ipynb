{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHjEwJl01xE_",
        "colab_type": "text"
      },
      "source": [
        "### Training a single recurrent neuron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whuS7vSS12MP",
        "colab_type": "text"
      },
      "source": [
        "We define a recurrent neuron as follows: <br>\n",
        "$y_{t+1} = 0.5y_t + 0.5x_t$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QZuQZ8Y2MGr",
        "colab_type": "text"
      },
      "source": [
        "### Generate Data\n",
        "Start with $y_0$ = $0$ <br>\n",
        "Generate a series of random numbers $+1/-1$ with $50/50$ probability. This will constitute our input at each time step ($x_t$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD17aEE_cZWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KxA7SCO062E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_inputs(n):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    n: int\n",
        "\n",
        "  Outputs: \n",
        "    x_t : list of length n with either +1 or -1 generated randomly with 50/50 probability\n",
        "  \"\"\"\n",
        "  x_t=[]\n",
        "  p=0\n",
        "  q=0\n",
        "  while(p+q<n):\n",
        "    a=np.random.choice([-1,1])\n",
        "    if(a==1 and p<(n/2)):\n",
        "      x_t.append(a)\n",
        "      p+=1\n",
        "    elif(a==-1 and q<(n/2)):\n",
        "      x_t.append(a)\n",
        "      q+=1\n",
        "  return x_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Jo5tPm7S0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_outputs(x_t):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    x_t: list of length n with inputs to recurrent neuron\n",
        "\n",
        "  Outputs:\n",
        "    y_t : list of length n+1 with outputs generated using our definition of recurrent neuron \n",
        "  \"\"\"\n",
        "  y_t=np.zeros(len(x_t)+1)\n",
        "  for i in range (0,len(x_t)):\n",
        "    if(i==0):\n",
        "      y_t[1]=0.5*x_t[0]\n",
        "    else:\n",
        "      y_t[i+1]=0.5*y_t[i]+0.5*x_t[i]\n",
        "  return y_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyDMlVkK7yMR",
        "colab_type": "text"
      },
      "source": [
        "### Training using BPTT\n",
        "Write the train function that takes $y_t$ and $x_t$, starts with random values of $w$ and $g$ where \n",
        "$$\n",
        "y_{t+1} = wx_{t} + gy_t\n",
        "$$\n",
        "and trains using BPTT to find values of $w$ and $g$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37MeIOak80R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_bptt(x_t, y_t, time_steps, epochs):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    x_t: list of length n with inputs to recurrent neuron\n",
        "    y_t: list of length n+1 with outputs\n",
        "    time_steps: int, number of timesteps to roll the rnn and do bptt\n",
        "    epochs: number of epochs to train the rnn for\n",
        "  \n",
        "  Outputs:\n",
        "    w, g: trained parameters of the model\n",
        "  \"\"\"\n",
        "  w=np.random.uniform(0,1)\n",
        "  g=np.random.uniform(0,1)\n",
        "  h_t=np.zeros(len(x_t)+1)\n",
        "  yd_t=np.zeros(len(x_t)+1)\n",
        "  t=0\n",
        "  n=0\n",
        "  del_w=0\n",
        "  del_g=0\n",
        "  while(n<epochs):\n",
        "    for i in range (t,t+time_steps):\n",
        "      if(i==0):\n",
        "        yd_t[1]=w*x_t[0]\n",
        "        t+=1\n",
        "      else:\n",
        "        yd_t[i+1]=g*y_t[i]+w*x_t[i]\n",
        "        t+1\n",
        "    for k in range (1,time_steps+1):\n",
        "      if(k==time_steps):\n",
        "        del_w+=0.5*(yd_t[k]-y_t[k])*x_t[k-1]\n",
        "        del_g+=0.5*(yd_t[k]-y_t[k])*y_t[k-1]\n",
        "      else:\n",
        "        del_w+=0.5*((yd_t[k]-y_t[k])+(yd_t[time_steps]-y_t[time_steps])*(g**(time_steps-k)))*x_t[k-1]\n",
        "        del_g+=0.5*((yd_t[k]-y_t[k])+(yd_t[time_steps]-y_t[time_steps])*(g**(time_steps-k)))*y_t[k-1]\n",
        "    w=w-del_w\n",
        "    g=g-del_g\n",
        "    n+=1\n",
        "\n",
        "  return w,g\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSegBAQ-ZIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92c13c17-79fa-4725-a445-380208e320ef"
      },
      "source": [
        "train_bptt([-1, -1, -1, 1, 1, -1, 1, -1, 1, 1],[ 0.        , -0.5       , -0.75      , -0.875     ,  0.0625    ,\n",
        "        0.53125   , -0.234375  ,  0.3828125 , -0.30859375,  0.34570312,\n",
        "        0.67285156],2,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5039490124609706, 0.4628885623651138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    }
  ]
}