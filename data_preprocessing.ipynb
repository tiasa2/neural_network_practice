{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Quiz 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1y00BqjpyTP",
        "colab_type": "text"
      },
      "source": [
        "##1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YWHjWjtp9Bz",
        "colab_type": "text"
      },
      "source": [
        "###Q. Generate Random points\n",
        "Write a function that takes parameters $r_1$, $r_2$, $n$ $(r_2 > r_1 > 0)$ and generates random points $(x_1, x_2)$ as follows - \n",
        "- $n$ random points that lie within a circle with center at $(0, 0)$ and radius $r_1$ $\\rightarrow$ These points belong to class ```'inner'```\n",
        "- $n$ random points that lie outside circle with center at $(0, 0)$ and radius $r_1$ but inside circle with center at $(0, 0)$ and radius $r_2$ $\\rightarrow$ These points belong to class ```'outer'```\n",
        "\n",
        "The function gen_random should return $X$, $Cls$ :\n",
        "- $X$ is a numpy array of shape $(2n, 2)$ which has the $2n$ random points generated as above\n",
        "- $Cls$ is a numpy array of shape $(2n,)$ which contains the value of the class corresponding to each point in $X$ (values will be either ```'inner'``` or ```'outer'```)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WWEUIetpA04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math as mt\n",
        "def gen_random_points(r1, r2, n):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    r1 : float\n",
        "    r2 : float, r2 > r1\n",
        "    n : int, number of points\n",
        "  Outputs:\n",
        "    X : numpy array, shape -> (2n, 2)\n",
        "    Cls : numpy array, shape -> (2n, )\n",
        "  \"\"\"\n",
        "  X=[]\n",
        "  Cls=[]\n",
        "  count=0\n",
        "  inn=0\n",
        "  out=0\n",
        "  X=np.array(X)\n",
        "  X=np.zeros((2*n,2))\n",
        "  while (count<(2*n)):\n",
        "    i=np.random.randint(low=0, high=r2, size=1)\n",
        "    j=np.random.randint(low=0, high=r2, size=1)\n",
        "    if (mt.sqrt((i**2)+(j**2))<r1 and inn<n):\n",
        "      X[count,0]=i\n",
        "      X[count,1]=j\n",
        "      Cls.append('inner')\n",
        "      inn+=1\n",
        "      count+=1\n",
        "    elif(mt.sqrt((i**2)+(j**2))<r2 and out<n):\n",
        "      X[count,0]=i\n",
        "      X[count,1]=j\n",
        "      Cls.append('outer')\n",
        "      out+=1\n",
        "      count+=1\n",
        "  Cls=np.array(Cls)\n",
        "  return (X, Cls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQEovtnWvF1E",
        "colab_type": "text"
      },
      "source": [
        "##2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZnBaClDvJbp",
        "colab_type": "text"
      },
      "source": [
        "###Q. One-hot encode\n",
        "Write a function that takes a numpy array $Cls$ of shape $(n, )$ which contains class labels of $n$ samples of data and creates a numpy array, $Y_d$ of shape $(n, \\text{unique})$ containing 1-hot representations of the $n$ samples. Here $\\text{unique}$ is the number of unique classes in $Cls$. <br>\n",
        "The function should return two values - \n",
        "- $Y_d$ - numpy array of shape $(n, \\text{unique})$ with 1-hot representations\n",
        "- ```cls_order``` - numpy array of shape $(\\text{unique}, )$ which contains the labels of the classes in the order in which they occur in the 1-hot representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLB75bffvIne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def one_hot_encode(Cls):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    Cls: numpy array, shape: (n, ) contains class labels of n data samples\n",
        "  Outputs:\n",
        "    Yd : numpy array of shape (n, unique)\n",
        "    cls_order: numpy array of shape(unique, )\n",
        "  \"\"\"\n",
        "  ar=[]\n",
        "  Yd=[]\n",
        "  cls_order=[]\n",
        "  Cls=np.array(Cls)\n",
        "  Yd=np.array(Yd)\n",
        "  cls_order=np.array(cls_order)\n",
        "  for k in Cls:\n",
        "    if k not in ar:\n",
        "      ar.append(k)\n",
        "  ar=np.array(ar)\n",
        "  unique=len(ar)\n",
        "  x=len(Cls)\n",
        "  Yd=np.zeros((x,unique))\n",
        "  for i in range (0,x):\n",
        "    for j in range (0,unique):\n",
        "      if(ar[j]==Cls[i]):\n",
        "        Yd[i,j]+=1\n",
        "  np.reshape(ar,(unique,))\n",
        "  return(Yd, ar)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFD0WNUbzYUo",
        "colab_type": "text"
      },
      "source": [
        "##3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTczqgGRzZ-K",
        "colab_type": "text"
      },
      "source": [
        "###Q. Softmax\n",
        "Write a function that takes a vector (numpy array of shape $(f,)$) - $(y_{in})$ and returns the result vector (numpy array of shape $(f,)$) - $(y_{out})$ of applying the softmax non-linearity to it. <br>\n",
        "$$\n",
        "y_{out}^{i} = \\frac{e^{y_{in}^{i}}}{\\sum_{i=1}^{f}e^{y_{in}^{i}}}\n",
        "$$ \n",
        "\n",
        "where $y^{i}$ refers to the $i^{th}$ component of vector $y$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6jF41px0EAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def softmax(y_in):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    y_in : numpy array of shape (f, ), input vector \n",
        "  Outputs:\n",
        "    y_out : numpy array of shape(f, ), output vector\n",
        "  \"\"\"\n",
        "  sum_=0\n",
        "  t=0\n",
        "  y_out=[]\n",
        "  y_in=np.array(y_in)\n",
        "  for i in range(0,len(y_in)):\n",
        "    sum_+=np.exp(y_in[i])\n",
        "  for i in range(0,len(y_in)):\n",
        "    y_out.append((np.exp(y_in[i]))/sum_)\n",
        "  y_out=np.array(y_out)\n",
        "  return y_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymfyiNKzoep",
        "colab_type": "text"
      },
      "source": [
        "##4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgvyBiO2zttQ",
        "colab_type": "text"
      },
      "source": [
        "###Q. Standardize\n",
        "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{stdz}$  after standardizing $X$ where\n",
        "$$\n",
        "  X_{stdz}^i = \\frac{X^i - \\mu(X)}{\\sigma(X)}\n",
        "$$\n",
        "where $\\mu(X)$ is the feature-wise mean of all samples in $X$ and $\\sigma(X)$ is feature-wise standard deviation of all samples in $X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLIHeN-3G1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def standardize(X):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    X: numpy array of shape (n, f)\n",
        "  Outputs:\n",
        "    X_stdz : numpy array of shape (n, f)\n",
        "  \"\"\"\n",
        "  X=np.array(X)\n",
        "  n=X.shape[0]\n",
        "  f=X.shape[1]\n",
        "  mean=[]\n",
        "  std_dev=[]\n",
        "  X_stdz=[]\n",
        "  mean=np.array(mean)\n",
        "  std_dev=np.array(std_dev)\n",
        "  mean=np.mean(X,axis=1)\n",
        "  std_dev=np.std(X,axis=1)\n",
        "  X_stdz=np.array(X_stdz)\n",
        "  X_stdz=np.zeros((n,f))\n",
        "  for i in range (0,n):\n",
        "    for j in range (0,f):\n",
        "      X_stdz[i,j]=((X[i,j]-mean[i])/std_dev[i])\n",
        "  return X_stdz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kazu6ZCf7xVU",
        "colab_type": "text"
      },
      "source": [
        "##5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oPGUWp37y63",
        "colab_type": "text"
      },
      "source": [
        "###Q. Normalize\n",
        "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{normd}$  after normalizing $X$ where\n",
        "$$\n",
        "  X_{normd}^i = \\frac{X^i - \\min(X)}{max(X) - min(X)}\n",
        "$$\n",
        "where $\\max(X)$ is the feature-wise maximum of all samples in $X$ and $min(X)$ is feature-wise minimum of all samples in $X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC3cuVxU-vSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def normalize(X):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    X: numpy array of shape (n, f)\n",
        "  Outputs:\n",
        "    X_normd : numpy array of shape (n, f)\n",
        "  \"\"\"\n",
        "  X=np.array(X)\n",
        "  n=X.shape[0]\n",
        "  f=X.shape[1]\n",
        "  X_normd=[]\n",
        "  max_=[]\n",
        "  min_=[]\n",
        "  X_normd=np.array(X_normd)\n",
        "  max_=np.array(max_)\n",
        "  min_=np.array(min_)\n",
        "  max_=np.amax(X,axis=1)\n",
        "  min_=np.amin(X,axis=1)\n",
        "  X_normd=np.zeros((n,f))\n",
        "  for i in range(0,n):\n",
        "    for j in range(0,f):\n",
        "      X_normd[i,j]=((X[i,j]-min_[i])/(max_[i]-min_[i]))\n",
        "  return X_normd  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}